# CNN
A simple CNN implementing various tricks to make it deeper. 
This was made for a university project, the pptx was made for it as well and contains a brief description of the network and the results. Around 90% was achieved on CIFAR-10 dataset.
The network is partially based on SimpleNet and implements several other ideas to make it deeper:
- Residual connections
- BatchNorm
- Fractional Pooling
It also uses the Swish activation function instead of the simpler ReLU.
Although it did not achieve such a great result, it was useful to gain some confidence with TensorFlow and CNNs.
